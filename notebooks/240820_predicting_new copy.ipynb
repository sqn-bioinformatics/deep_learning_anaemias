{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand the dataset by classifying using MobileNetv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2024-08-19\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MobileNetV2 was trained on 1000 labelled images from Cytopix and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rc(\"axes\", labelsize=14, titlesize=14)\n",
    "plt.rc(\"legend\", fontsize=14)\n",
    "plt.rc(\"xtick\", labelsize=10)\n",
    "plt.rc(\"ytick\", labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 10:56:36.635431: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-20 10:56:36.651787: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-20 10:56:36.673387: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-20 10:56:36.673413: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-20 10:56:36.688041: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-20 10:56:37.436047: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     " raises-exception"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/home/t.afanasyeva/deep_learning_anaemias/resources/out/cytpix/24-Survive-017_sorted'\n",
      "[Errno 17] File exists: '/home/t.afanasyeva/deep_learning_anaemias/resources/out/cytpix/24-Survive-017_sorted/discocyte'\n",
      "[Errno 17] File exists: '/home/t.afanasyeva/deep_learning_anaemias/resources/out/cytpix/24-Survive-017_sorted/echinocyte'\n",
      "[Errno 17] File exists: '/home/t.afanasyeva/deep_learning_anaemias/resources/out/cytpix/24-Survive-017_sorted/granular'\n",
      "[Errno 17] File exists: '/home/t.afanasyeva/deep_learning_anaemias/resources/out/cytpix/24-Survive-017_sorted/holly_leaf'\n",
      "[Errno 17] File exists: '/home/t.afanasyeva/deep_learning_anaemias/resources/out/cytpix/24-Survive-017_sorted/sickle'\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_NAME = \"24-Survive-017\"\n",
    "LOCAION_IN = \"resources/out/cytpix\"\n",
    "LOCAION_OUT = \"resources/out/cytpix\"\n",
    "\n",
    "folder_class_names = [\"discocyte\", \"echinocyte\", \"granular\", \"holly_leaf\", \"sickle\"]\n",
    "sorted_dir = SAMPLE_NAME + \"_sorted\"\n",
    "path_out = Path.cwd().parent / LOCAION_OUT / sorted_dir\n",
    "\n",
    "try:\n",
    "    path_out.mkdir(parents=False, exist_ok=False)\n",
    "except FileExistsError as e:\n",
    "    print(f\"{e}\")\n",
    "finally:\n",
    "    for item in folder_class_names:\n",
    "        path_folder = path_out / item\n",
    "        try:\n",
    "            path_folder.mkdir()\n",
    "        except FileExistsError as e:\n",
    "            print(f\"{e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23655 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 10:56:38.859855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13764 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (24, 96, 96, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 10:56:40.173667: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import (\n",
    "    Rescaling,\n",
    "    RandomFlip,\n",
    "    RandomRotation,\n",
    "    RandomTranslation,\n",
    "    RandomContrast,\n",
    "    RandomBrightness,\n",
    ")\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "IMG_SIZE = (96, 96)\n",
    "BATCH_SIZE = 24\n",
    "path_in = Path.cwd().parent / LOCAION_IN / SAMPLE_NAME\n",
    "file_names = [image.stem for image in path_in.iterdir()]\n",
    "\n",
    "test_ds = keras.utils.image_dataset_from_directory(\n",
    "    path_in,\n",
    "    labels=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=None,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=93,\n",
    "    data_format=\"channels_last\",\n",
    "    verbose=True,\n",
    ")\n",
    "class_names = test_ds.class_names\n",
    "\n",
    "rescale = tf.keras.Sequential([Rescaling(1.0 / 255)])\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        RandomFlip(\"horizontal_and_vertical\"),\n",
    "        RandomRotation(0.2),\n",
    "        RandomTranslation(0.2, 0.2),\n",
    "        RandomContrast(0.2),\n",
    "        RandomBrightness(0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def prepare(ds, batch_size):\n",
    "\n",
    "    ds = ds.map(lambda x: rescale(x), num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(batch_size, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    return ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "test_ds = prepare(\n",
    "    test_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "for data in test_ds.take(1):\n",
    "    print(f\"Test data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate model and load weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t.afanasyeva/miniforge3/envs/IMG/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 210 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_96             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,405</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenetv2_1.00_96             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m6,405\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,264,389</span> (8.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,264,389\u001b[0m (8.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,230,277</span> (8.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,230,277\u001b[0m (8.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,112</span> (133.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,112\u001b[0m (133.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    BatchNormalization,\n",
    "    ReLU,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "\n",
    "mobile_net = keras.applications.MobileNetV2(\n",
    "    input_shape=(96, 96, 3),\n",
    "    alpha=1.0,\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(mobile_net)\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.build((None, 96, 96, 3))\n",
    "model_path = Path.cwd().parent / \"model_zoo\" / \"mobile_net_v04.weights.h5\"\n",
    "model.load_weights(\n",
    "    model_path,\n",
    "    skip_mismatch=False,\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict new images from test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724144201.963117  636726 service.cc:145] XLA service 0x7fbf7c0027d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1724144201.963175  636726 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-08-20 10:56:42.003857: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-20 10:56:42.346100: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 27/986\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 6ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1724144204.192995  636726 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m986/986\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23655"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_ds)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get class names from integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {\n",
    "    0: \"discocyte\",\n",
    "    1: \"holly_leaf\",\n",
    "    2: \"granular\",\n",
    "    3: \"sickle\",\n",
    "    4: \"echinocyte\",\n",
    "}\n",
    "y_pred = [name_dict[k] for k in y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write images to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = \".png\"\n",
    "\n",
    "for name, prediction in zip(file_names, y_pred):\n",
    "    image_path_in = str(path_in / (name + extension))\n",
    "    img = cv2.imread(image_path_in)\n",
    "    image_path_out = str(path_out / prediction / (name + extension))\n",
    "    cv2.imwrite(image_path_out, img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
