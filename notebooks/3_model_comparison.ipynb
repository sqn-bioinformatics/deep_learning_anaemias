{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare several models EfficientNet, MobileNetV2, and ResNetV2 on the ImageStream dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06-02-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rc(\"axes\", labelsize=14, titlesize=14)\n",
    "plt.rc(\"legend\", fontsize=14)\n",
    "plt.rc(\"xtick\", labelsize=10)\n",
    "plt.rc(\"ytick\", labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-08 00:05:33.365042: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-08 00:05:33.380007: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1738969533.397043 2199522 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1738969533.402234 2199522 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-08 00:05:33.420002: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "keras.backend.clear_session()\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.applications.inception_v3 import (\n",
    "    preprocess_input as inceptionV3_preprocess_input,\n",
    ")\n",
    "from keras.applications.resnet_v2 import preprocess_input as resnet50v2_preprocess_input\n",
    "from keras.applications.mobilenet_v2 import (\n",
    "    preprocess_input as mobilenetv2_preprocess_input,\n",
    ")\n",
    "from keras.applications.efficientnet import (\n",
    "    preprocess_input as efficientnetb0_preprocess_input,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(model_name, y_test, y_pred, class_names):\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(8, 8))\n",
    "    cm = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        ax=ax,\n",
    "        xticks_rotation=\"vertical\",\n",
    "        colorbar=False,\n",
    "        normalize=\"true\",\n",
    "        display_labels=class_names,\n",
    "    )\n",
    "\n",
    "    plt.rc(\"font\", size=12)\n",
    "    ax.set_title(f\"Confusion Matrix {model_name}\")\n",
    "    plt.savefig(f\"confusion_matrix_{model_name}.png\")\n",
    "\n",
    "\n",
    "def plot_history(model_name, history, metrics):\n",
    "    sns.lineplot(data=history[metrics[0]], label=metrics[0])\n",
    "    sns.lineplot(data=history[metrics[1]], label=metrics[1])\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"metric\")\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.savefig(\n",
    "        f\"/home/t.afanasyeva/deep_learning_anaemias/output/{model_name}_{metrics}_history.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetoday = pd.to_datetime(\"today\").strftime(\"%Y%m%d\")\n",
    "\n",
    "path_in = Path.cwd().parent / \"resources/imagestream\"\n",
    "path_out = Path.cwd().parent / f\"{datetoday}_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18237 files belonging to 6 classes.\n",
      "Using 14590 files for training.\n",
      "Using 3647 files for validation.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "\n",
    "train_ds, test_ds = keras.utils.image_dataset_from_directory(\n",
    "    path_in,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=[\n",
    "        \"discocyte\",\n",
    "        \"sidewaydiscocytes\",\n",
    "        \"holly_leaf\",\n",
    "        \"granular\",\n",
    "        \"sickle\",\n",
    "        \"echinocyte\",\n",
    "    ],\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=None,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    shuffle=True,\n",
    "    seed=93,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    data_format=\"channels_last\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "data_augmentation1 = Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "    ]\n",
    ")\n",
    "data_augmentation2 = Sequential(\n",
    "    [\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "    ]\n",
    ")\n",
    "data_augmentation3 = Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(),\n",
    "    ]\n",
    ")\n",
    "data_augmentation4 = Sequential(\n",
    "    [\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "class_names = test_ds.class_names\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (tf.image.grayscale_to_rgb(x), y), num_parallel_calls=AUTOTUNE\n",
    ")\n",
    "test_ds = test_ds.map(\n",
    "    lambda x, y: (tf.image.grayscale_to_rgb(x), y), num_parallel_calls=AUTOTUNE\n",
    ")\n",
    "\n",
    "train_ds1 = train_ds.map(\n",
    "    lambda x, y: (data_augmentation1(x, training=True), y),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    ")\n",
    "train_ds2 = train_ds.map(\n",
    "    lambda x, y: (data_augmentation2(x, training=True), y),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    ")\n",
    "train_ds3 = train_ds.map(\n",
    "    lambda x, y: (data_augmentation3(x, training=True), y),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    ")\n",
    "train_ds4 = train_ds.map(\n",
    "    lambda x, y: (data_augmentation4(x, training=True), y),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    ")\n",
    "\n",
    "ds_list = [train_ds, train_ds1, train_ds2, train_ds3, train_ds4]\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices(ds_list)\n",
    "train_ds = ds.interleave(\n",
    "    lambda x: x,\n",
    "    cycle_length=1,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['discocyte',\n",
       " 'sidewaydiscocytes',\n",
       " 'holly_leaf',\n",
       " 'granular',\n",
       " 'sickle',\n",
       " 'echinocyte']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.save(\"/home/t.afanasyeva/deep_learning_anaemias/output/train_ds\")\n",
    "test_ds.save(\"/home/t.afanasyeva/deep_learning_anaemias/output/test_ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 18:57:48.570280: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for data, label in test_ds.take(1):\n",
    "    print(f\"Test data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow((images[i].numpy()).astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i].numpy().argmax()])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_ds.take(1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    first_image = image[0]\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "        plt.imshow(augmented_image[0], cmap=\"gray\")\n",
    "        plt.title(class_names[label.numpy().argmax()])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up models to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopper = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, verbose=3, mode=\"min\", restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "def learning_rate_schedule(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return (lr * tf.math.exp(0.5)).numpy()\n",
    "    if epoch < 15:\n",
    "        return lr\n",
    "    else:\n",
    "        return (lr * tf.math.exp(-0.1)).numpy()\n",
    "\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(learning_rate_schedule)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input_dict = {\n",
    "    \"ResNet50V2\": resnet50v2_preprocess_input,\n",
    "    \"MobileNetV2\": mobilenetv2_preprocess_input,\n",
    "    \"EfficientNetB0\": efficientnetb0_preprocess_input,\n",
    "    \"InceptionV3\": inceptionV3_preprocess_input,\n",
    "}\n",
    "models_dict = {\n",
    "    \"ResNet50V2\": keras.applications.ResNet50V2,\n",
    "    \"MobileNetV2\": keras.applications.MobileNetV2,\n",
    "    \"EfficientNetB0\": keras.applications.EfficientNetB0,\n",
    "    \"InceptionV3\": keras.applications.InceptionV3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet50V2...\n",
      "Output: 2048\n",
      "Output of Dense2: 1024\n",
      "Preprocessed ResNet50V2 data\n",
      "Compiled ResNet50V2 model\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1738951099.169032 2118621 service.cc:148] XLA service 0x7f794c001f70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1738951099.169064 2118621 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2025-02-07 18:58:20.512307: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1738951104.582764 2118621 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1738951130.504198 2118621 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2280/Unknown \u001b[1m763s\u001b[0m 309ms/step - accuracy: 0.6054 - loss: 3.9238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 19:10:34.196211: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-02-07 19:10:34.196275: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 18205867421552285127\n",
      "2025-02-07 19:10:34.196319: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1372863871257842498\n",
      "/home/t.afanasyeva/miniforge3/envs/IMG/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m788s\u001b[0m 319ms/step - accuracy: 0.6054 - loss: 3.9231 - val_accuracy: 0.2580 - val_loss: 3.7873 - learning_rate: 0.0165\n",
      "Epoch 2/200\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.8209 - loss: 0.8700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 19:22:37.644560: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 291ms/step - accuracy: 0.8209 - loss: 0.8700 - val_accuracy: 0.1259 - val_loss: 3.2838 - learning_rate: 0.0272\n",
      "Epoch 3/200\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 294ms/step - accuracy: 0.8529 - loss: 2.0315 - val_accuracy: 0.6696 - val_loss: 1.9105 - learning_rate: 0.0448\n",
      "Epoch 4/200\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.8546 - loss: 4.8157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 19:44:48.039690: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m660s\u001b[0m 289ms/step - accuracy: 0.8546 - loss: 4.8144 - val_accuracy: 0.3809 - val_loss: 11.4036 - learning_rate: 0.0739\n",
      "Epoch 5/200\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 287ms/step - accuracy: 0.8475 - loss: 11.6884 - val_accuracy: 0.3507 - val_loss: 4.1738 - learning_rate: 0.1218\n",
      "Epoch 6/200\n",
      "\u001b[1m2280/2280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.8804 - loss: 1.6615"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    ReLU,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "from keras import regularizers\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "\n",
    "results = {}\n",
    "history_dict = {}\n",
    "\n",
    "for model_name, model_class in models_dict.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    base_model = model_class(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "        pooling=\"None\",\n",
    "        classes=6,\n",
    "        classifier_activation=\"softmax\",\n",
    "    )\n",
    "    # print(base_model.summary())\n",
    "    base_model.trainable = True\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    print(f\"Output: {base_model.output_shape[-1]}\")\n",
    "\n",
    "    model.add(\n",
    "        Dense(base_model.output_shape[-1], kernel_regularizer=regularizers.L2(0.01))\n",
    "    )\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(\n",
    "        Dense(\n",
    "            (base_model.output_shape[-1] // 2), kernel_regularizer=regularizers.L2(0.01)\n",
    "        )\n",
    "    )\n",
    "    print(f\"Output of Dense2: {base_model.output_shape[-1]//2}\")\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(Dense(124, kernel_regularizer=regularizers.L2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(6, activation=\"softmax\"))\n",
    "\n",
    "    preprocess_input = preprocess_input_dict[model_name]\n",
    "\n",
    "    train_ds = (\n",
    "        train_ds.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls=AUTOTUNE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    test_ds = (\n",
    "        test_ds.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls=AUTOTUNE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    print(f\"Preprocessed {model_name} data\")\n",
    "\n",
    "    with tf.device(\"GPU:0\"):\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=CategoricalCrossentropy(from_logits=False),\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        print(f\"Compiled {model_name} model\")\n",
    "\n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=test_ds,\n",
    "            callbacks=[earlystopper, lr_scheduler],\n",
    "            epochs=EPOCHS,\n",
    "            validation_freq=1,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        model.save(\n",
    "            f\"/home/t.afanasyeva/deep_learning_anaemias/output/250205_{model_name}.keras\"\n",
    "        )\n",
    "    y_test = tf.concat([y for _, y in test_ds], axis=0)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "    y_pred = model.predict(test_ds)\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "    accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    f1_score_model = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    scores = {\n",
    "        \"test_balanced_accuracy\": accuracy,\n",
    "        \"test_f1_weighted\": f1_score_model,\n",
    "        \"test_precision_weighted\": precision,\n",
    "        \"test_recall_weighted\": recall,\n",
    "    }\n",
    "\n",
    "    results[model_name] = {\"scores\": scores}\n",
    "    history_dict[model_name] = {\"history\": history.history}\n",
    "    get_confusion_matrix(model_name, y_test, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({k: v[\"scores\"] for k, v in results.items()}).T\n",
    "results_df.to_csv(path_out / f\"results_{datetoday}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, _ in models_dict.items():\n",
    "    history = history_dict[model_name][\"history\"]\n",
    "    history[\"val_loss\"] = [val for val in history[\"val_loss\"] for _ in range(2)]\n",
    "    history[\"val_accuracy\"] = [val for val in history[\"val_accuracy\"] for _ in range(2)]\n",
    "    plot_history(model_name, history, [\"loss\", \"val_loss\"])\n",
    "    plot_history(model_name, history, [\"accuracy\", \"val_accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IMG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
