{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c50bcc65",
   "metadata": {},
   "source": [
    "# Training DLN model on both datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7074a676",
   "metadata": {},
   "source": [
    "15-04-2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d381ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63b83370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rc(\"axes\", labelsize=14, titlesize=14)\n",
    "plt.rc(\"legend\", fontsize=14)\n",
    "plt.rc(\"xtick\", labelsize=10)\n",
    "plt.rc(\"ytick\", labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "503dce4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "keras.backend.clear_session()\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "185d047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import (\n",
    "    RandomRotation,\n",
    "    RandomTranslation,\n",
    "    RandomFlip,\n",
    "    RandomContrast,\n",
    "    Dense,\n",
    "    ReLU,\n",
    "    BatchNormalization,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "from keras.regularizers import L2\n",
    "\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.applications.inception_v3 import (\n",
    "    preprocess_input as inceptionV3_preprocess_input,\n",
    ")\n",
    "from keras.applications.resnet_v2 import preprocess_input as resnet50v2_preprocess_input\n",
    "from keras.applications.mobilenet_v2 import (\n",
    "    preprocess_input as mobilenetv2_preprocess_input,\n",
    ")\n",
    "from keras.applications.efficientnet import (\n",
    "    preprocess_input as efficientnetb0_preprocess_input,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    "    ConfusionMatrixDisplay,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da9aca",
   "metadata": {},
   "source": [
    "Defining custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fdddb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(model_name, y_test, y_pred, class_names):\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(8, 8))\n",
    "    cm = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        ax=ax,\n",
    "        xticks_rotation=\"vertical\",\n",
    "        colorbar=False,\n",
    "        normalize=\"true\",\n",
    "        display_labels=class_names,\n",
    "    )\n",
    "\n",
    "    plt.rc(\"font\", size=12)\n",
    "    ax.set_title(f\"Confusion Matrix {model_name}\")\n",
    "    plt.savefig(f\"confusion_matrix_{model_name}.png\")\n",
    "\n",
    "\n",
    "def plot_history(model_name, history, metrics):\n",
    "    sns.lineplot(data=history[metrics[0]], label=metrics[0])\n",
    "    sns.lineplot(data=history[metrics[1]], label=metrics[1])\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"metric\")\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.savefig(\n",
    "        f\"/home/t.afanasyeva/deep_learning_anaemias/output/{model_name}_{metrics}_history.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df94e7",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cfc81c",
   "metadata": {},
   "source": [
    "loading Imagestream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39b7d70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "\n",
    "\n",
    "def expand_ds(train_ds):\n",
    "    \"\"\"\n",
    "    Expands a training dataset by applying a series of data augmentation transformations.\n",
    "\n",
    "    Args:\n",
    "        train_ds: A TensorFlow dataset containing training data.\n",
    "\n",
    "    Returns:\n",
    "        A TensorFlow dataset with augmented data, interleaved with the original dataset.\n",
    "    \"\"\"\n",
    "    data_augmentation_list = [\n",
    "        Sequential([RandomRotation(factor=0.15)]),\n",
    "        Sequential([RandomTranslation(height_factor=0.1, width_factor=0.1)]),\n",
    "        Sequential([RandomFlip()]),\n",
    "        Sequential([RandomContrast(factor=0.1)]),\n",
    "    ]\n",
    "\n",
    "    ds_list = [\n",
    "        train_ds.map(\n",
    "            lambda x, y: (data_augmentation(x, training=True), y),\n",
    "            num_parallel_calls=AUTOTUNE,\n",
    "        )\n",
    "        for data_augmentation in data_augmentation_list\n",
    "    ]\n",
    "    ds_list.append(train_ds)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(ds_list)\n",
    "    train_ds = ds.interleave(\n",
    "        lambda x: x,\n",
    "        cycle_length=1,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE,\n",
    "    )\n",
    "    return train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "099a4a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_source_channel(image_tensor, source_id):\n",
    "    \"\"\"\n",
    "    Adds a channel to the image that encodes the source dataset\n",
    "\n",
    "    Args:\n",
    "        image_tensor: A tensor of shape [H, W, C]\n",
    "        source_id: The dataset identifier value to fill the new channel with\n",
    "\n",
    "    Returns:\n",
    "        A tensor with an additional channel containing the source_id value\n",
    "    \"\"\"\n",
    "\n",
    "    # Assuming [H, W, C] format (TensorFlow standard)\n",
    "    H, W, C = image_tensor.shape\n",
    "\n",
    "    source_channel = tf.ones((H, W, 1), dtype=image_tensor.dtype) * source_id\n",
    "    augmented_tensor = tf.concat([image_tensor, source_channel], axis=2)\n",
    "\n",
    "    return augmented_tensor\n",
    "\n",
    "\n",
    "# Example in a dataset pipeline\n",
    "def add_source_to_dataset(image, label, source_id):\n",
    "    image_with_source = add_source_channel(image, source_id)\n",
    "    return image_with_source, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01c3f80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18237 files belonging to 5 classes.\n",
      "Using 14590 files for training.\n",
      "Using 3647 files for validation.\n"
     ]
    }
   ],
   "source": [
    "path_in = Path.cwd().parent / \"resources/imagestream\"\n",
    "\n",
    "train_ds_im, test_ds_im = keras.utils.image_dataset_from_directory(\n",
    "    path_in,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=[\n",
    "        \"discocyte\",\n",
    "        \"holly_leaf\",\n",
    "        \"granular\",\n",
    "        \"sickle\",\n",
    "        \"echinocyte\",\n",
    "    ],\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=None,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    shuffle=True,\n",
    "    seed=93,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    data_format=\"channels_last\",\n",
    "    verbose=True,\n",
    ")\n",
    "class_names = test_ds_im.class_names\n",
    "\n",
    "train_ds_im, test_ds_im = [\n",
    "    ds.map(lambda x, y: (tf.image.grayscale_to_rgb(x), y), num_parallel_calls=AUTOTUNE)\n",
    "    for ds in (train_ds_im, test_ds_im)\n",
    "]\n",
    "train_ds_im = expand_ds(train_ds_im)\n",
    "train_ds_im = train_ds_im.map(\n",
    "    lambda x, y: (add_source_to_dataset(x, y, 1)),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b40b6c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15000 files belonging to 5 classes.\n",
      "Using 12000 files for training.\n",
      "Using 3000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "path_in_cp = Path.cwd().parent / \"resources/cytpix/augmented\"\n",
    "\n",
    "train_ds_cp, test_ds_cp = keras.utils.image_dataset_from_directory(\n",
    "    path_in_cp,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=[\n",
    "        \"discocyte\",\n",
    "        \"holly_leaf\",\n",
    "        \"granular\",\n",
    "        \"sickle\",\n",
    "        \"echinocyte\",\n",
    "    ],\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=None,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    shuffle=True,\n",
    "    seed=93,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    data_format=\"channels_last\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "train_ds_cp, test_ds_cp = [\n",
    "    ds.map(lambda x, y: (tf.image.grayscale_to_rgb(x), y), num_parallel_calls=AUTOTUNE)\n",
    "    for ds in (train_ds_cp, test_ds_cp)\n",
    "]\n",
    "train_ds_cp = expand_ds(train_ds_cp)\n",
    "train_ds_cp = train_ds_cp.map(\n",
    "    lambda x, y: (add_source_to_dataset(x, y, 1)),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    ")\n",
    "test_ds_cp = test_ds_cp.map(\n",
    "    lambda x, y: (add_source_to_dataset(x, y, 1)),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94a92f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.sample_from_datasets(\n",
    "    [train_ds_im, train_ds_cp], weights=[0.5, 0.5], seed=42\n",
    ").shuffle(buffer_size=25000)\n",
    "\n",
    "test_ds = tf.data.Dataset.sample_from_datasets(\n",
    "    [test_ds_im, test_ds_cp], weights=[0.5, 0.5]\n",
    ").shuffle(buffer_size=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbe21db",
   "metadata": {},
   "source": [
    "## Set up models to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa014df",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopper = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, verbose=3, mode=\"min\", restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "def learning_rate_schedule(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return (lr * tf.math.exp(0.5)).numpy()\n",
    "    if epoch < 15:\n",
    "        return lr\n",
    "    else:\n",
    "        return (lr * tf.math.exp(-0.1)).numpy()\n",
    "\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(learning_rate_schedule)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a45da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "415d325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input_dict = {\n",
    "    \"ResNet50V2\": resnet50v2_preprocess_input,\n",
    "    \"MobileNetV2\": mobilenetv2_preprocess_input,\n",
    "    \"EfficientNetB0\": efficientnetb0_preprocess_input,\n",
    "    \"InceptionV3\": inceptionV3_preprocess_input,\n",
    "}\n",
    "models_dict = {\n",
    "    \"ResNet50V2\": keras.applications.ResNet50V2,\n",
    "    \"MobileNetV2\": keras.applications.MobileNetV2,\n",
    "    \"EfficientNetB0\": keras.applications.EfficientNetB0,\n",
    "    \"InceptionV3\": keras.applications.InceptionV3,\n",
    "}\n",
    "\n",
    "results = {}\n",
    "history_dict = {}\n",
    "\n",
    "path_out = Path.cwd().parent / f\"output/{datetime.now().strftime('%y%m%d')}_output\"\n",
    "path_out.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b67344",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_class in models_dict.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    base_model = model_class(\n",
    "        include_top=False,\n",
    "        weights=None,\n",
    "        input_tensor=None,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 4),\n",
    "        pooling=\"None\",\n",
    "        classes=5,\n",
    "        classifier_activation=\"softmax\",\n",
    "    )\n",
    "    # print(base_model.summary())\n",
    "    base_model.trainable = True\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "\n",
    "    model.add(Dense(base_model.output_shape[-1], kernel_regularizer=L2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(Dense((base_model.output_shape[-1] // 2), kernel_regularizer=L2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(Dense(124, kernel_regularizer=L2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(5, activation=\"softmax\"))\n",
    "\n",
    "    preprocess_input = preprocess_input_dict[model_name]\n",
    "\n",
    "    train_ds_processed = (\n",
    "        train_ds.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls=AUTOTUNE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(AUTOTUNE)\n",
    "    )\n",
    "    test_ds_processed = (\n",
    "        test_ds.map(lambda x, y: (preprocess_input(x), y), num_parallel_calls=AUTOTUNE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    print(f\"Preprocessed {model_name} data\")\n",
    "\n",
    "    with tf.device(\"GPU:0\"):\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=CategoricalCrossentropy(from_logits=False),\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        print(f\"Compiled {model_name} model\")\n",
    "\n",
    "        history = model.fit(\n",
    "            train_ds_processed,\n",
    "            validation_data=test_ds_processed,\n",
    "            callbacks=[earlystopper, lr_scheduler],\n",
    "            epochs=EPOCHS,\n",
    "            validation_freq=1,\n",
    "        )\n",
    "        model.save(path_out / f\"{model_name}.keras\")\n",
    "\n",
    "    y_test = tf.concat([y for _, y in test_ds_processed], axis=0)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "    y_pred = model.predict(test_ds_processed)\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "    accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    f1_score_model = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    scores = {\n",
    "        \"test_balanced_accuracy\": accuracy,\n",
    "        \"test_f1_weighted\": f1_score_model,\n",
    "        \"test_precision_weighted\": precision,\n",
    "        \"test_recall_weighted\": recall,\n",
    "    }\n",
    "\n",
    "    results[model_name] = {\"scores\": scores}\n",
    "    history_dict[model_name] = {\"history\": history.history}\n",
    "    get_confusion_matrix(model_name, y_test, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1843f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame({k: v[\"scores\"] for k, v in results.items()}).T\n",
    "results_df.to_csv(path_out/\"models_results.csv\", index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf0e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, _ in models_dict.items():\n",
    "    history = history_dict[model_name][\"history\"]\n",
    "    history[\"val_loss\"] = [val for val in history[\"val_loss\"] for _ in range(2)]\n",
    "    history[\"val_accuracy\"] = [val for val in history[\"val_accuracy\"] for _ in range(2)]\n",
    "    plot_history(model_name, history, [\"loss\", \"val_loss\"])\n",
    "    plot_history(model_name, history, [\"accuracy\", \"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db36f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image, label in train_ds_im.take(1):\n",
    "#     print(\"Image shape:\", image.shape)\n",
    "#     print(\"Label shape:\", label.shape)\n",
    "\n",
    "# image, label = next(iter(train_ds_im))\n",
    "# plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "\n",
    "# def add_source_channel(image_tensor, source_id):\n",
    "#     \"\"\"\n",
    "#     Adds a channel to the image that encodes the source dataset\n",
    "\n",
    "#     Args:\n",
    "#         image_tensor: A tensor of shape [H, W, C]\n",
    "#         source_id: The dataset identifier value to fill the new channel with\n",
    "\n",
    "#     Returns:\n",
    "#         A tensor withe bottom row black or white  based on source_id\n",
    "#         \"\"\"\n",
    "#     # Assuming [H, W, C] format (TensorFlow standard)\n",
    "#     H, W, C = image_tensor.shape\n",
    "\n",
    "#     bottom_row_color_by_source_id = tf.zeros((1, W, C), dtype=image_tensor.dtype) if source_id == 1 else tf.ones((1, W, C), dtype=image_tensor.dtype)\n",
    "#     augmented_tensor = tf.concat([image_tensor[:-1, :, :], bottom_row_color_by_source_id], axis=0)\n",
    "\n",
    "#     return augmented_tensor\n",
    "\n",
    "# aug_image = add_source_channel(image, 0)\n",
    "# plt.imshow(aug_image.numpy().astype(\"uint8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IMG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
