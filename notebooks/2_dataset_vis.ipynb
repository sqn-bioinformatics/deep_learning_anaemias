{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path += [os.path.abspath(\"../src\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing import image as tf_image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (combine_images_for_all_patients.py, line 15)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniforge3/envs/IMG/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3579\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 1\u001b[0;36m\n\u001b[0;31m    import combine_images_for_all_patients as combine_images\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/deep_learning_anaemias/src/combine_images_for_all_patients.py:15\u001b[0;36m\u001b[0m\n\u001b[0;31m    def main(path_in: str, path_out: str) --> DataFrame:\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "import combine_images_for_all_patients as combine_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths= \"/home/t.afanasyeva/research_storage/Processing/Lab - Van Dam/datasets/srf_anaemias/CytPix/processed\"\n",
    "p = Path(\"/home/t.afanasyeva/deep_learning_anaemias\")\n",
    "# path_out = p / \"resources/cytpix/combined\"\n",
    "path_out = p / \"resources/trial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_counts = pd.read_csv(\n",
    "    \"/home/t.afanasyeva/deep_learning_anaemias/output/250205_cell_count_per_patient.csv\",\n",
    "    index_col=0,\n",
    "    names=[\"patient_id\", \"cell_type\", \"count\"],\n",
    "    skiprows=1,\n",
    ")\n",
    "\n",
    "patient_counts[\"patient_id\"] = patient_counts[\"patient_id\"].str.replace(\"_sorted\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_counts_agg = (\n",
    "    patient_counts.groupby(\"patient_id\").agg({\"count\": \"sum\"}).reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_counts_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did not included all 24-711122 and 23-714262 discocytes in this dataset, so we need to get the counts out of general population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_counts[\n",
    "    (patient_counts[\"patient_id\"] == \"24-711122\")\n",
    "    & (\n",
    "        patient_counts[\"cell_type\"].isin(\n",
    "            [\"echinocyte\", \"granular\", \"holly_leaf\", \"sickle\"]\n",
    "        )\n",
    "    )\n",
    "].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_24_711122_disc = 13793 - 278\n",
    "patient_counts.loc[\n",
    "    (patient_counts[\"patient_id\"] == \"24-711122\")\n",
    "    & (patient_counts[\"cell_type\"] == \"discocyte\"),\n",
    "    \"count\",\n",
    "] = new_24_711122_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_counts[\n",
    "    (patient_counts[\"patient_id\"] == \"23-714262\")\n",
    "    & (\n",
    "        patient_counts[\"cell_type\"].isin(\n",
    "            [\"echinocyte\", \"granular\", \"holly_leaf\", \"sickle\"]\n",
    "        )\n",
    "    )\n",
    "].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_714262_disc = 21682 - 2309\n",
    "patient_counts.loc[\n",
    "    (patient_counts[\"patient_id\"] == \"23-714262*\")\n",
    "    & (patient_counts[\"cell_type\"] == \"discocyte\"),\n",
    "    \"count\",\n",
    "] = new_714262_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired order of cell types\n",
    "cell_type_order = [\"discocyte\", \"granular\", \"holly_leaf\", \"sickle\", \"echinocyte\"]\n",
    "\n",
    "# Convert the 'cell_type' column to a categorical type with the specified order\n",
    "patient_counts[\"cell_type\"] = pd.Categorical(\n",
    "    patient_counts[\"cell_type\"], categories=cell_type_order, ordered=True\n",
    ")\n",
    "\n",
    "# Sort the dataframe by 'patient_id' and 'cell_type'\n",
    "patient_counts = patient_counts.sort_values(by=[\"patient_id\", \"cell_type\"]).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "patient_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the dataframe to get the counts for each cell type per patient\n",
    "pivot_df = patient_counts.pivot(\n",
    "    index=\"patient_id\", columns=\"cell_type\", values=\"count\"\n",
    ").fillna(0)\n",
    "\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total counts for each patient\n",
    "df_total = pivot_df.sum(axis=1)\n",
    "\n",
    "# Calculate the relative percentages\n",
    "df_rel = pivot_df.div(df_total, axis=0) * 100\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot each cell type as a stacked bar with thicker bars\n",
    "bottom = np.zeros(len(pivot_df))\n",
    "for cell_type in cell_type_order:\n",
    "    ax.bar(\n",
    "        pivot_df.index,\n",
    "        pivot_df[cell_type],\n",
    "        label=cell_type,\n",
    "        bottom=bottom,\n",
    "        width=0.5,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    bottom += pivot_df[cell_type]\n",
    "\n",
    "# Add percentage labels to the bars\n",
    "for cell_type in df_rel:\n",
    "    for i, (cs, ab, pc) in enumerate(\n",
    "        zip(pivot_df.cumsum(axis=1)[cell_type], pivot_df[cell_type], df_rel[cell_type])\n",
    "    ):\n",
    "        ax.text(i, cs - ab / 2, str(np.round(pc, 1)) + \"%\", va=\"center\", ha=\"center\")\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xlabel(\"Patient ID\")\n",
    "ax.legend(\n",
    "    title=\"Cell Type\", bbox_to_anchor=(1.05, 1), loc=\"upper left\"\n",
    ")  # Move legend outside\n",
    "\n",
    "# Show the plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\n",
    "    \"/home/t.afanasyeva/deep_learning_anaemias/output/250205_cell_count_per_patient.png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new order of columns\n",
    "new_order = [\"discocyte\", \"granular\", \"holly_leaf\", \"sickle\", \"echinocyte\"]\n",
    "\n",
    "# Reorder the columns\n",
    "pivot_df = pivot_df[new_order]\n",
    "\n",
    "# Display the DataFrame to verify the new order\n",
    "pivot_df\n",
    "\n",
    "# pivot_df.to_csv(\"/home/t.afanasyeva/deep_learning_anaemias/output/250205_cell_count_per_patient_pivot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.aggregate([\"sum\"]).to_csv(\n",
    "    \"/home/t.afanasyeva/deep_learning_anaemias/output/250205_cell_count_per_patient_pivot_sum.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the total counts for each patient\n",
    "df_total = pivot_df.sum(axis=1)\n",
    "\n",
    "# Calculate the relative percentages\n",
    "df_rel = pivot_df.div(df_total, axis=0) * 100\n",
    "\n",
    "# Create a figure with subplots for each patient\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot a pie chart for each patient\n",
    "for i, patient_id in enumerate(pivot_df.index):\n",
    "    ax = axes[i]\n",
    "    y = pivot_df.loc[patient_id].values\n",
    "    porcent = 100.0 * y / y.sum()\n",
    "    patches, texts = ax.pie(y, startangle=90, radius=1.2)\n",
    "    labels = [\n",
    "        \"{0} - {1:1.2f} %\".format(i, j) for i, j in zip(pivot_df.columns, porcent)\n",
    "    ]\n",
    "\n",
    "    # Sort legend\n",
    "    patches, labels, dummy = zip(\n",
    "        *sorted(zip(patches, labels, y), key=lambda x: x[2], reverse=True)\n",
    "    )\n",
    "\n",
    "    ax.legend(\n",
    "        patches, labels, loc=\"center left\", bbox_to_anchor=(-0.4, 0.5), fontsize=12\n",
    "    )  # Increased fontsize and moved legend outside left\n",
    "    ax.set_title(patient_id)\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust layout with padding\n",
    "plt.subplots_adjust(left=0.1, right=0.9, wspace=0.4)\n",
    "plt.savefig(\n",
    "    \"/home/t.afanasyeva/deep_learning_anaemias/output/250205_cell_count_per_patient_pie.png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Create a barplot with thicker bars\n",
    "plt.figure(figsize=(12, 8))\n",
    "g = sns.catplot(\n",
    "    kind=\"swarm\",\n",
    "    data=patient_counts,\n",
    "    x=\"patient_id\",\n",
    "    y=\"count\",\n",
    "    hue=\"cell_type\",\n",
    "    log_scale=True,\n",
    "    size=8,\n",
    ")\n",
    "\n",
    "# Add labels and legend\n",
    "plt.ylabel(\"Count (ln-transformed)\")\n",
    "plt.xlabel(\"Patient ID\")\n",
    "plt.xticks(rotation=45)\n",
    "# plt.legend(\n",
    "#     title=\"Cell Type\", bbox_to_anchor=(1.05, 1), loc=\"upper left\"\n",
    "# )\n",
    "g.despine(right=True)\n",
    "\n",
    "plt.savefig(\n",
    "    \"/home/t.afanasyeva/deep_learning_anaemias/output/250205_cell_count_per_patient_ln.png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_counts[patient_counts[\"cell_type\"] == \"sickle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient_counts.to_csv(\n",
    "#     \"/home/t.afanasyeva/deep_learning_anaemias/output/250205_cell_count_per_patient_adjsuted.csv\"\n",
    "# )\n",
    "del patient_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# import keras\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to hold images and labels\n",
    "X = []\n",
    "y = []\n",
    "z = []\n",
    "\n",
    "# Define the directory path\n",
    "directory_path = \"/home/t.afanasyeva/deep_learning_anaemias/resources/cytpix/combined\"\n",
    "\n",
    "# Iterate over each folder in the directory\n",
    "for folder_name in os.listdir(directory_path):\n",
    "    folder_path = os.path.join(directory_path, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Iterate over each file in the folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            if file_name.endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "                # Load the image\n",
    "                img = image.load_img(\n",
    "                    file_path, color_mode=\"grayscale\", target_size=(64, 64)\n",
    "                )\n",
    "                img_array = image.img_to_array(img)\n",
    "                img_array = img_array / 255.0  # Normalize the image\n",
    "\n",
    "                # Append the image, label, and file name to the lists\n",
    "                X.append(img_array)\n",
    "                y.append(folder_name)\n",
    "                z.append(file_name)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array([x.ravel() for x in X])\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Define the RandomUnderSampler with the desired sampling strategy\n",
    "rus = RandomUnderSampler(\n",
    "    sampling_strategy={\n",
    "        \"discocyte\": 3000,\n",
    "        \"echinocyte\": 664,\n",
    "        \"granular\": 1271,\n",
    "        \"holly_leaf\": 785,\n",
    "        \"sickle\": 1946,\n",
    "    },\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit and resample the data\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "\n",
    "\n",
    "# Get the indices of the original samples\n",
    "original_indices = rus.sample_indices_\n",
    "z_resampled = [z[i] for i in original_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"/home/t.afanasyeva/deep_learning_anaemias/resources/train\"\n",
    "image_shape = (64, 64)\n",
    "for i, img in enumerate(X_resampled):\n",
    "    img = img.reshape(image_shape)\n",
    "    folder = os.path.join(directory_path, y_resampled[i])\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    file_path = os.path.join(folder, z_resampled[i])\n",
    "    plt.imsave(file_path, img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the correct hashes are kept per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the flattened image array back to its original shape\n",
    "image_shape = (64, 64)\n",
    "image = X_resampled[7].reshape(image_shape)\n",
    "\n",
    "print(z_resampled[8])\n",
    "# Display the image using OpenCV\n",
    "plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_check = \"94332ccb832fa351fe807d4bd60377f2.png\"\n",
    "folder_to_check = (\n",
    "    \"/home/t.afanasyeva/deep_learning_anaemias/resources/cytpix/combined/discocyte\"\n",
    ")\n",
    "file_path_to_check = os.path.join(folder_to_check, file_to_check)\n",
    "\n",
    "file_exists = os.path.exists(file_path_to_check)\n",
    "file_exists\n",
    "if file_exists:\n",
    "    img = plt.imread(file_path_to_check)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(file_to_check)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"File {file_to_check} does not exist in the folder {folder_to_check}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating extra oversampled files with os_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize lists to hold images and labels\n",
    "# X = []\n",
    "# y = []\n",
    "# z = []\n",
    "\n",
    "# # Define the directory path\n",
    "# directory_path = \"/home/t.afanasyeva/deep_learning_anaemias/resources/train\"\n",
    "\n",
    "# # Iterate over each folder in the directory\n",
    "# for folder_name in os.listdir(directory_path):\n",
    "#     folder_path = os.path.join(directory_path, folder_name)\n",
    "#     if os.path.isdir(folder_path):\n",
    "#         # Iterate over each file in the folder\n",
    "#         for file_name in os.listdir(folder_path):\n",
    "#             file_path = os.path.join(folder_path, file_name)\n",
    "#             if file_name.endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "#                 # Load the image using matplotlib\n",
    "#                 img = plt.imread(file_path)\n",
    "#                 # Append the image, label, and file name to the lists\n",
    "#                 X.append(img_array)\n",
    "#                 y.append(folder_name)\n",
    "#                 z.append(file_name)\n",
    "\n",
    "# # Convert lists to numpy arrays\n",
    "# X_resampled = np.array([x.ravel() for x in X])\n",
    "# y_resampled = np.array(y)\n",
    "# z_resampled = np.array(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Define the RandomOverSampler with the desired sampling strategy\n",
    "ros = RandomOverSampler(\n",
    "    sampling_strategy={\n",
    "        \"discocyte\": 3000,\n",
    "        \"echinocyte\": 1000,\n",
    "        \"granular\": 2000,\n",
    "        \"holly_leaf\": 1000,\n",
    "        \"sickle\": 2000,\n",
    "    },\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit and resample the data\n",
    "X_oversampled, y_oversampled = ros.fit_resample(X_resampled, y_resampled)\n",
    "ros_indices = ros.sample_indices_\n",
    "z_oversampled = [z_resampled[i] for i in ros_indices]\n",
    "\n",
    "print(sorted(Counter(y_oversampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count the occurrences of each file name in z_oversampled\n",
    "file_counts = Counter(z_oversampled)\n",
    "\n",
    "# Find duplicates\n",
    "duplicates = [file for file, count in file_counts.items() if count > 1]\n",
    "\n",
    "print(f\"Number of replicas: {len(duplicates)}\")\n",
    "print(\"Duplicate files:\", duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create a dictionary to map original file names to resampled file names\n",
    "file_name_mapping = {}\n",
    "\n",
    "# Define the directory path for saving oversampled images\n",
    "save_directory_path = \"/home/t.afanasyeva/deep_learning_anaemias/resources/train\"\n",
    "\n",
    "# Iterate over each oversampled image and save it with the specified prefix\n",
    "for i, image in enumerate(X_oversampled):\n",
    "    image = image.reshape(image_shape)\n",
    "    folder = os.path.join(save_directory_path, y_oversampled[i])\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    original_file_name = z_oversampled[i]\n",
    "    file_path = os.path.join(folder, original_file_name)\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(file_path):\n",
    "        file_name = f\"os_{original_file_name}\"\n",
    "        counter = 1\n",
    "        while os.path.exists(os.path.join(folder, file_name)):\n",
    "            file_name = f\"os{counter}_{original_file_name}\"\n",
    "            counter += 1\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "    else:\n",
    "        file_name = original_file_name\n",
    "\n",
    "    plt.imsave(file_path, image, cmap=\"gray\")\n",
    "\n",
    "    # Update the mapping dictionary\n",
    "    file_name_mapping[original_file_name] = file_name\n",
    "\n",
    "# Save the mapping dictionary to a file for future reference\n",
    "mapping_file_path = (\n",
    "    \"/home/t.afanasyeva/deep_learning_anaemias/output/file_name_mapping.json\"\n",
    ")\n",
    "with open(mapping_file_path, \"w\") as f:\n",
    "    json.dump(file_name_mapping, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to hold images and labels\n",
    "X = []\n",
    "y = []\n",
    "z = []\n",
    "\n",
    "# Define the directory path\n",
    "directory_path = \"/home/t.afanasyeva/deep_learning_anaemias/resources/train\"\n",
    "\n",
    "# Iterate over each folder in the directory\n",
    "for folder_name in os.listdir(directory_path):\n",
    "    folder_path = os.path.join(directory_path, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Iterate over each file in the folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            if file_name.endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "                # Load the image\n",
    "                img = tf_image.load_img(\n",
    "                    file_path, color_mode=\"grayscale\", target_size=(64, 64)\n",
    "                )\n",
    "                img_array = tf_image.img_to_array(img)\n",
    "\n",
    "                # Append the image, label, and file name to the lists\n",
    "                X.append(img_array)\n",
    "                y.append(folder_name)\n",
    "                z.append(file_name)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = Counter(y)\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the images labeled as \"granular\"\n",
    "echinocyte_indices = np.where(y == \"echinocyte\")[0]\n",
    "\n",
    "# Filter the X array to get only the images labeled as \"granular\"\n",
    "X_echinocyte = X[echinocyte_indices]\n",
    "\n",
    "X_echinocyte.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_echinocyte[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline for echinocytes and holly leafs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each folder in the directory\n",
    "path_in = \"/home/t.afanasyeva/deep_learning_anaemias/resources/train\"\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "\n",
    "ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    path_in,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=[\"echinocyte\", \"holly_leaf\"],\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=None,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    shuffle=True,\n",
    "    seed=93,\n",
    "    subset=None,\n",
    "    data_format=\"channels_last\",\n",
    "    verbose=True,\n",
    ")\n",
    "class_names = ds.class_names\n",
    "\n",
    "data_augmentation1 = Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "        layers.RandomZoom(height_factor=(-0.1, -0.05), width_factor=(-0.1, -0.05)),\n",
    "    ]\n",
    ")\n",
    "data_augmentation2 = Sequential(\n",
    "    [\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        layers.RandomZoom(height_factor=(-0.1, -0.05), width_factor=(-0.1, -0.05)),\n",
    "    ]\n",
    ")\n",
    "data_augmentation3 = Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(),\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "        layers.RandomZoom(height_factor=(-0.1, -0.05), width_factor=(-0.1, -0.05)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds = ds.map(lambda x, y: (tf.image.grayscale_to_rgb(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "ds1 = ds.map(\n",
    "    lambda x, y: (data_augmentation1(x, training=True), y),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    ")\n",
    "ds2 = ds.map(\n",
    "    lambda x, y: (data_augmentation2(x, training=True), y),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    ")\n",
    "ds3 = ds.map(\n",
    "    lambda x, y: (data_augmentation3(x, training=True), y),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    ")\n",
    "\n",
    "\n",
    "ds_list = [ds1, ds2, ds3]\n",
    "ds_new = tf.data.Dataset.from_tensor_slices(ds_list)\n",
    "ds_aug = ds_new.interleave(\n",
    "    lambda x: x,\n",
    "    cycle_length=1,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ").shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = sum(1 for _ in ds_aug)\n",
    "print(\"Dataset size:\", size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure to display the images\n",
    "fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
    "\n",
    "# Iterate over the dataset and display 20 random images\n",
    "for i, (image, label) in enumerate(ds_aug.take(20)):\n",
    "    ax = axes[i // 5, i % 5]\n",
    "    ax.imshow(image.numpy().astype(\"uint8\"))\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(class_names[tf.argmax(label).numpy()])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/t.afanasyeva/deep_learning_anaemias/resources/cytpix/augmented\"\n",
    "\n",
    "for i, (image, label) in enumerate(ds_aug):\n",
    "    class_index = tf.argmax(label).numpy()\n",
    "    folder_name = class_names[class_index]\n",
    "    folder_path = os.path.join(output_dir, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    save_path = os.path.join(folder_path, f\"{i}.png\")\n",
    "    plt.imsave(save_path, image.numpy().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aug for sickle and granular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each folder in the directory\n",
    "path_in = \"/home/t.afanasyeva/deep_learning_anaemias/resources/train\"\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "\n",
    "ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    path_in,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=[\"sickle\", \"granular\"],\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=None,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    shuffle=True,\n",
    "    seed=93,\n",
    "    subset=None,\n",
    "    data_format=\"channels_last\",\n",
    "    verbose=True,\n",
    ")\n",
    "class_names = ds.class_names\n",
    "\n",
    "data_augmentation1 = Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        layers.RandomZoom(height_factor=(-0.1, -0.05), width_factor=(-0.1, -0.05)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_augmentation2 = Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(),\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "        layers.RandomZoom(height_factor=(-0.1, -0.05), width_factor=(-0.1, -0.05)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds = ds.map(lambda x, y: (tf.image.grayscale_to_rgb(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Shuffle the datasets\n",
    "ds1 = ds.map(\n",
    "    lambda x, y: (data_augmentation1(x, training=True), y),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    ").shuffle(1000)\n",
    "\n",
    "ds2 = ds.map(\n",
    "    lambda x, y: (data_augmentation2(x, training=True), y),\n",
    "    num_parallel_calls=AUTOTUNE,\n",
    ").shuffle(1000)\n",
    "\n",
    "# Take half of each dataset\n",
    "ds = ds.take(len(ds2) // 2)\n",
    "ds1 = ds1.take(len(ds1) // 2)\n",
    "ds2 = ds2.take(len(ds2) // 2)\n",
    "\n",
    "\n",
    "ds_list = [ds, ds1, ds2]\n",
    "ds_new = tf.data.Dataset.from_tensor_slices(ds_list)\n",
    "ds_aug = ds_new.interleave(\n",
    "    lambda x: x,\n",
    "    cycle_length=1,\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ").shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = sum(1 for _ in ds_aug)\n",
    "print(\"Dataset size:\", size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Define your augmentation pipelines\n",
    "data_augmentation1 = Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        layers.RandomZoom(height_factor=(-0.1, -0.05), width_factor=(-0.1, -0.05)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_augmentation2 = Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(),\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "        layers.RandomZoom(height_factor=(-0.1, -0.05), width_factor=(-0.1, -0.05)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load a sample image (replace with your image path)\n",
    "img_path = \"/home/t.afanasyeva/deep_learning_anaemias/resources/train/holly_leaf/2f07f9e06ec66f56034f413a8a66e551.png\"  # Change to your image path\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "# Apply augmentations\n",
    "augmented_image1 = data_augmentation1(img_array)\n",
    "augmented_image2 = data_augmentation2(img_array)\n",
    "\n",
    "# Plot original and augmented images\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Original Image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_array[0].astype(\"uint8\"))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Augmented Image 1\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(augmented_image1[0].numpy().astype(\"uint8\"))\n",
    "plt.title(\"Augmented Image 1\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Augmented Image 2\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(augmented_image2[0].numpy().astype(\"uint8\"))\n",
    "plt.title(\"Augmented Image 2\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure to display the images\n",
    "fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
    "\n",
    "# Iterate over the dataset and display 20 random images\n",
    "for i, (image, label) in enumerate(ds_aug.take(20)):\n",
    "    ax = axes[i // 5, i % 5]\n",
    "    ax.imshow(image.numpy().astype(\"uint8\"))\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(class_names[tf.argmax(label).numpy()])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/t.afanasyeva/deep_learning_anaemias/resources/cytpix/augmented\"\n",
    "\n",
    "for i, (image, label) in enumerate(ds_aug):\n",
    "    class_index = tf.argmax(label).numpy()\n",
    "    folder_name = class_names[class_index]\n",
    "    folder_path = os.path.join(output_dir, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    save_path = os.path.join(folder_path, f\"{i}.png\")\n",
    "    plt.imsave(save_path, image.numpy().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define source and destination directories\n",
    "src_dir = \"/home/t.afanasyeva/deep_learning_anaemias/resources/train/discocyte\"\n",
    "dst_dir = (\n",
    "    \"/home/t.afanasyeva/deep_learning_anaemias/resources/cytpix/augmented/discocyte\"\n",
    ")\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "# Copy all PNG files from the source to the destination directory\n",
    "for file_name in os.listdir(src_dir):\n",
    "    if file_name.endswith(\".png\"):\n",
    "        src_file = os.path.join(src_dir, file_name)\n",
    "        dst_file = os.path.join(dst_dir, file_name)\n",
    "        shutil.copy(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_in = \"/home/t.afanasyeva/deep_learning_anaemias/resources/cytpix/augmented\"\n",
    "ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    path_in,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=[\n",
    "        \"discocyte\",\n",
    "        \"holly_leaf\",\n",
    "        \"granular\",\n",
    "        \"sickle\",\n",
    "        \"echinocyte\",\n",
    "    ],\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=None,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    shuffle=True,\n",
    "    seed=93,\n",
    "    subset=None,\n",
    "    data_format=\"channels_last\",\n",
    "    verbose=True,\n",
    ")\n",
    "class_names = ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in ds.take(1):\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure to display the images\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "# Iterate over the dataset and display 9 random images\n",
    "for i, (image, label) in enumerate(ds.take(9)):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    ax.imshow(image.numpy().astype(\"uint8\"))\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\n",
    "        class_names[tf.argmax(label).numpy()], fontsize=16\n",
    "    )  # Increased fontsize\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\n",
    "    \"/home/t.afanasyeva/deep_learning_anaemias/output/250208_augmented_images.png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make extra graph for the ImageStream Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the folders\n",
    "path_to_folders = \"/home/t.afanasyeva/deep_learning_anaemias/resources/imagestream\"\n",
    "\n",
    "# Get the list of folders\n",
    "folders = [\n",
    "    f\n",
    "    for f in os.listdir(path_to_folders)\n",
    "    if os.path.isdir(os.path.join(path_to_folders, f))\n",
    "]\n",
    "\n",
    "# Count the items in each folder\n",
    "folder_counts = {\n",
    "    folder: len(os.listdir(os.path.join(path_to_folders, folder))) for folder in folders\n",
    "}\n",
    "\n",
    "# Create a DataFrame with the counts\n",
    "df_folder_counts = pd.DataFrame([folder_counts])\n",
    "print(df_folder_counts)\n",
    "\n",
    "# Calculate the total counts\n",
    "df_total = df_folder_counts.sum(axis=1)\n",
    "\n",
    "# Calculate the relative percentages\n",
    "df_rel = df_folder_counts.div(df_total, axis=0) * 100\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Define the order of cell types\n",
    "cell_type_order = df_folder_counts.columns\n",
    "\n",
    "# Plot each cell type as a stacked bar with thicker bars\n",
    "bottom = np.zeros(len(df_folder_counts))\n",
    "for cell_type in cell_type_order:\n",
    "    ax.bar(\n",
    "        df_folder_counts.index,\n",
    "        df_folder_counts[cell_type],\n",
    "        label=cell_type,\n",
    "        bottom=bottom,\n",
    "        width=0.5,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    bottom += df_folder_counts[cell_type]\n",
    "\n",
    "# Add percentage labels to the bars\n",
    "for cell_type in df_rel:\n",
    "    for i, (cs, ab, pc) in enumerate(\n",
    "        zip(\n",
    "            df_folder_counts.cumsum(axis=1)[cell_type],\n",
    "            df_folder_counts[cell_type],\n",
    "            df_rel[cell_type],\n",
    "        )\n",
    "    ):\n",
    "        ax.text(i, cs - ab / 2, str(np.round(pc, 1)) + \"%\", va=\"center\", ha=\"center\")\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.legend(\n",
    "    title=\"Cell Type\", bbox_to_anchor=(1.05, 1), loc=\"upper left\"\n",
    ")  # Move legend outside\n",
    "\n",
    "# Remove x label, x ticks, and despine on the left\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_xticks([])\n",
    "sns.despine(ax=ax, left=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\n",
    "    \"/home/t.afanasyeva/deep_learning_anaemias/output/250206_cell_count_imagestraem.png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the path to the folders\n",
    "path_to_folders = \"/home/t.afanasyeva/deep_learning_anaemias/resources/imagestream\"\n",
    "\n",
    "# Get the list of folders\n",
    "folders = [\n",
    "    f\n",
    "    for f in os.listdir(path_to_folders)\n",
    "    if os.path.isdir(os.path.join(path_to_folders, f))\n",
    "]\n",
    "\n",
    "# Count the items in each folder\n",
    "folder_counts = {\n",
    "    folder: len(os.listdir(os.path.join(path_to_folders, folder))) for folder in folders\n",
    "}\n",
    "\n",
    "# Create a DataFrame with the counts\n",
    "df_folder_counts = pd.DataFrame([folder_counts])\n",
    "print(df_folder_counts)\n",
    "\n",
    "# Calculate the total counts\n",
    "df_total = df_folder_counts.sum(axis=1)\n",
    "\n",
    "# Calculate the relative percentages\n",
    "df_rel = df_folder_counts.div(df_total, axis=0) * 100\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Define the order of cell types\n",
    "cell_type_order = df_folder_counts.columns\n",
    "\n",
    "# Plot each cell type as a separate bar\n",
    "for cell_type in cell_type_order:\n",
    "    count = df_folder_counts[cell_type][0]\n",
    "    ax.bar(\n",
    "        cell_type,\n",
    "        count,\n",
    "        label=cell_type,\n",
    "        width=0.5,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    ax.text(cell_type, count, str(count), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.legend(\n",
    "    title=\"Cell Type\", bbox_to_anchor=(1.05, 1), loc=\"upper left\"\n",
    ")  # Move legend outside\n",
    "\n",
    "# Show the plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\n",
    "    \"/home/t.afanasyeva/deep_learning_anaemias/output/250206_cell_count_imagestraem.png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the path to the folders\n",
    "path_to_folders = \"/home/t.afanasyeva/deep_learning_anaemias/resources/train\"\n",
    "\n",
    "# Get the list of folders\n",
    "folders = [\n",
    "    f\n",
    "    for f in os.listdir(path_to_folders)\n",
    "    if os.path.isdir(os.path.join(path_to_folders, f))\n",
    "]\n",
    "\n",
    "# Count the items in each folder\n",
    "folder_counts = {\n",
    "    folder: len(os.listdir(os.path.join(path_to_folders, folder))) for folder in folders\n",
    "}\n",
    "\n",
    "# Create a DataFrame with the counts\n",
    "df_folder_counts = pd.DataFrame([folder_counts])\n",
    "print(df_folder_counts)\n",
    "\n",
    "# Calculate the total counts\n",
    "df_total = df_folder_counts.sum(axis=1)\n",
    "\n",
    "# Define the new order of columns\n",
    "new_order = [\"discocyte\", \"granular\", \"holly_leaf\", \"sickle\", \"echinocyte\"]\n",
    "\n",
    "\n",
    "# # Calculate the relative percentages\n",
    "# df_rel = df_folder_counts.div(df_total, axis=0) * 100\n",
    "\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Define the order of cell types\n",
    "cell_type_order = new_order\n",
    "\n",
    "# Plot each cell type as a separate bar\n",
    "for cell_type in cell_type_order:\n",
    "    count = df_folder_counts[cell_type][0]\n",
    "    ax.bar(\n",
    "        cell_type,\n",
    "        count,\n",
    "        label=cell_type,\n",
    "        width=0.5,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    ax.text(cell_type, count, str(count), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.legend(\n",
    "    title=\"Cell Type\", bbox_to_anchor=(1.05, 1), loc=\"upper left\"\n",
    ")  # Move legend outside\n",
    "\n",
    "# Show the plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\n",
    "    \"/home/t.afanasyeva/deep_learning_anaemias/output/250206_cell_count_imagestraem.png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot each cell type as a stacked bar with thicker bars\n",
    "bottom = np.zeros(len(df_total))\n",
    "for cell_type in cell_type_order:\n",
    "    ax.bar(\n",
    "        df_total.index,\n",
    "        df_folder_counts[cell_type],\n",
    "        label=cell_type,\n",
    "        bottom=bottom,\n",
    "        width=0.5,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    bottom += df_folder_counts[cell_type]\n",
    "\n",
    "# Add percentage labels to the bars\n",
    "for cell_type in df_rel:\n",
    "    for i, (cs, ab, pc) in enumerate(\n",
    "        zip(\n",
    "            df_folder_counts.cumsum(axis=1)[cell_type],\n",
    "            df_folder_counts[cell_type],\n",
    "            df_rel[cell_type],\n",
    "        )\n",
    "    ):\n",
    "        ax.text(i, cs - ab / 2, str(np.round(pc, 1)) + \"%\", va=\"center\", ha=\"center\")\n",
    "\n",
    "# Add labels and legend\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.legend(\n",
    "    title=\"Cell Type\", bbox_to_anchor=(1.05, 1), loc=\"upper left\"\n",
    ")  # Move legend outside\n",
    "\n",
    "# Remove x label, x ticks, and despine on the left\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_xticks([])\n",
    "sns.despine(ax=ax, left=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(\n",
    "    \"/home/t.afanasyeva/deep_learning_anaemias/output/250206_cell_count_cytpix_bar.png\",\n",
    "    bbox_inches=\"tight\",\n",
    "    dpi=300,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IMG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
